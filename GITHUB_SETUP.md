# ğŸš€ Guide de Configuration GitHub et Leaderboard

Ce guide vous explique comment mettre en place votre challenge sur GitHub avec un leaderboard automatique.

## ğŸ“‹ Ã‰tapes de Configuration

### 1. CrÃ©er le Repository GitHub

1. **CrÃ©er un nouveau repository sur GitHub:**
   - Allez sur [GitHub](https://github.com/new)
   - Nom: `gnn-role-transition-challenge` (ou votre choix)
   - Description: "GNN Challenge: Role Transition Prediction in Temporal Networks"
   - VisibilitÃ©: **Public** (pour que les participants puissent voir le leaderboard)
   - Ne pas initialiser avec README (vous avez dÃ©jÃ  un README)

2. **Initialiser Git localement et pousser:**
   ```bash
   cd "/home/sam/Desktop/GNNs BASIRA Lab/Pretraining/GNN Challenge"
   git init
   git add .
   git commit -m "Initial commit: GNN Challenge setup"
   git branch -M main
   git remote add origin https://github.com/VOTRE_USERNAME/gnn-role-transition-challenge.git
   git push -u origin main
   ```

### 2. Configurer GitHub Pages pour le Leaderboard

1. **Activer GitHub Pages:**
   - Allez dans **Settings** â†’ **Pages**
   - Source: **Deploy from a branch**
   - Branch: `main` / `/ (root)`
   - Cliquez **Save**

2. **Le leaderboard sera accessible Ã :**
   ```
   https://samuelmatia.github.io/gnn-role-transition-challenge/leaderboard.html
   ```

### 3. Configurer les Secrets (si nÃ©cessaire)

Si vous avez besoin d'accÃ©der Ã  des donnÃ©es privÃ©es dans GitHub Actions:

1. **Settings** â†’ **Secrets and variables** â†’ **Actions**
2. Ajoutez des secrets si nÃ©cessaire (ex: token pour tÃ©lÃ©charger les donnÃ©es)

### 4. Tester le Workflow

1. **CrÃ©er une soumission de test:**
   ```bash
   # Copier un fichier de soumission
   cp submissions/sample_submission_1.csv submissions/test_team.csv
   ```

2. **Pousser et vÃ©rifier:**
   ```bash
   git add submissions/test_team.csv
   git commit -m "Add test submission"
   git push
   ```

3. **VÃ©rifier que le workflow s'exÃ©cute:**
   - Allez dans l'onglet **Actions** de votre repository
   - Vous devriez voir le workflow "Update Leaderboard" s'exÃ©cuter

### 5. Ajouter le Lien du Leaderboard au README

Ajoutez ceci dans votre README.md (section appropriÃ©e):

```markdown
## ğŸ† Leaderboard

Le leaderboard est mis Ã  jour automatiquement Ã  chaque soumission.

ğŸ‘‰ **[Voir le Leaderboard](https://samuelmatia.github.io/gnn-role-transition-challenge/leaderboard.html)**
```

## ğŸ“ Instructions pour les Participants

### Comment Soumettre

1. **Fork le repository**
2. **CrÃ©er votre modÃ¨le** et gÃ©nÃ©rer vos prÃ©dictions
3. **Placer votre fichier CSV** dans `submissions/votre_equipe.csv`
4. **CrÃ©er une Pull Request** avec votre soumission
5. Le workflow GitHub Actions Ã©valuera automatiquement votre soumission
6. Si le score est valide, le leaderboard sera mis Ã  jour automatiquement

### Format de Soumission

- Fichier CSV avec colonnes: `user_id`, `snapshot_id`, `predicted_role`
- Nom du fichier: `submissions/team_name.csv` (remplacer `team_name` par votre nom d'Ã©quipe)
- Le `predicted_role` doit Ãªtre un entier entre 0 et 4

## ğŸ”§ Structure des Fichiers CrÃ©Ã©s

```
.github/
â””â”€â”€ workflows/
    â”œâ”€â”€ evaluate_submission.yml    # Ã‰value les soumissions via PR
    â””â”€â”€ update_leaderboard.yml     # Met Ã  jour le leaderboard

scripts/
â”œâ”€â”€ evaluate_all_submissions.py    # Ã‰value toutes les soumissions
â””â”€â”€ generate_leaderboard.py        # GÃ©nÃ¨re le leaderboard HTML/JSON

update_leaderboard.py              # Script de mise Ã  jour (alternative)
leaderboard.json                    # DonnÃ©es du leaderboard (gÃ©nÃ©rÃ©)
leaderboard.html                    # Page HTML du leaderboard (gÃ©nÃ©rÃ©)
```

## ğŸ› DÃ©pannage

### Le workflow ne s'exÃ©cute pas

1. VÃ©rifiez que les fichiers sont dans `.github/workflows/`
2. VÃ©rifiez la syntaxe YAML (pas d'erreurs d'indentation)
3. VÃ©rifiez que les chemins dans les workflows sont corrects

### Le leaderboard ne se met pas Ã  jour

1. VÃ©rifiez les logs du workflow dans l'onglet **Actions**
2. VÃ©rifiez que `leaderboard.json` et `leaderboard.html` sont bien commitÃ©s
3. VÃ©rifiez que GitHub Pages est activÃ©

### Erreurs d'Ã©valuation

1. VÃ©rifiez que les donnÃ©es de test sont dans `data/private/test.parquet`
2. VÃ©rifiez le format des fichiers CSV de soumission
3. VÃ©rifiez que toutes les dÃ©pendances sont dans `requirements.txt`

## ğŸ“Š Personnalisation du Leaderboard

Pour modifier l'apparence du leaderboard, Ã©ditez:
- `scripts/generate_leaderboard.py` â†’ fonction `generate_html()`

Pour modifier les mÃ©triques affichÃ©es, Ã©ditez:
- `scripts/generate_leaderboard.py` â†’ fonction `generate_leaderboard()`

## ğŸ”’ SÃ©curitÃ©

- Les donnÃ©es de test (`data/private/test.parquet`) ne doivent **JAMAIS** Ãªtre commitÃ©es
- Elles sont dans `.gitignore`
- Les participants ne doivent avoir accÃ¨s qu'aux features de test, pas aux labels

## âœ… Checklist Finale

- [ ] Repository GitHub crÃ©Ã©
- [ ] Code poussÃ© sur GitHub
- [ ] GitHub Pages activÃ©
- [ ] Workflow testÃ© avec une soumission
- [ ] Leaderboard accessible via GitHub Pages
- [ ] Lien du leaderboard ajoutÃ© au README
- [ ] Instructions de soumission ajoutÃ©es au README

---

**Besoin d'aide?** Ouvrez une issue sur le repository!

